{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ERJQX_DHKJ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bwblTT7HDb6"
      },
      "source": [
        "# Get Multi-Variate Time Series Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eir3-8C0G0A2",
        "outputId": "82d00fe5-ffa4-4036-e35c-cae1f1bd051f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-09 16:06:32--  https://s3-us-west-2.amazonaws.com/telemanom/data.zip\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.92.131.32, 3.5.80.142, 52.92.145.232, ...\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.92.131.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85899803 (82M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  81.92M  34.7MB/s    in 2.4s    \n",
            "\n",
            "2023-06-09 16:06:35 (34.7 MB/s) - ‘data.zip’ saved [85899803/85899803]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3-us-west-2.amazonaws.com/telemanom/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vZFLIvurHCCS"
      },
      "outputs": [],
      "source": [
        "!unzip -qq data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Wmw6SpHTEV",
        "outputId": "790b2990-a918-41c1-a137-d5ae33c63eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-05-19_15.00.10  test  train\n"
          ]
        }
      ],
      "source": [
        "!ls data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlVonDchHVPn",
        "outputId": "820e1444-c391-4b8b-9c5b-add680b9e32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A-1.npy  C-2.npy   D-5.npy   E-3.npy  F-5.npy  M-3.npy\t P-3.npy   T-3.npy\n",
            "A-2.npy  D-11.npy  D-6.npy   E-4.npy  F-7.npy  M-4.npy\t P-4.npy   T-4.npy\n",
            "A-3.npy  D-12.npy  D-7.npy   E-5.npy  F-8.npy  M-5.npy\t P-7.npy   T-5.npy\n",
            "A-4.npy  D-13.npy  D-8.npy   E-6.npy  G-1.npy  M-6.npy\t R-1.npy   T-8.npy\n",
            "A-5.npy  D-14.npy  D-9.npy   E-7.npy  G-2.npy  M-7.npy\t S-1.npy   T-9.npy\n",
            "A-6.npy  D-15.npy  E-10.npy  E-8.npy  G-3.npy  P-10.npy  S-2.npy\n",
            "A-7.npy  D-16.npy  E-11.npy  E-9.npy  G-4.npy  P-11.npy  T-10.npy\n",
            "A-8.npy  D-1.npy   E-12.npy  F-1.npy  G-6.npy  P-14.npy  T-12.npy\n",
            "A-9.npy  D-2.npy   E-13.npy  F-2.npy  G-7.npy  P-15.npy  T-13.npy\n",
            "B-1.npy  D-3.npy   E-1.npy   F-3.npy  M-1.npy  P-1.npy\t T-1.npy\n",
            "C-1.npy  D-4.npy   E-2.npy   F-4.npy  M-2.npy  P-2.npy\t T-2.npy\n"
          ]
        }
      ],
      "source": [
        "!ls data/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-bH7qt8HYIa",
        "outputId": "b1dbb100-378a-4161-d342-aabc61fa1861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A-1.npy  C-2.npy   D-5.npy   E-3.npy  F-5.npy  M-3.npy\t P-3.npy   T-3.npy\n",
            "A-2.npy  D-11.npy  D-6.npy   E-4.npy  F-7.npy  M-4.npy\t P-4.npy   T-4.npy\n",
            "A-3.npy  D-12.npy  D-7.npy   E-5.npy  F-8.npy  M-5.npy\t P-7.npy   T-5.npy\n",
            "A-4.npy  D-13.npy  D-8.npy   E-6.npy  G-1.npy  M-6.npy\t R-1.npy   T-8.npy\n",
            "A-5.npy  D-14.npy  D-9.npy   E-7.npy  G-2.npy  M-7.npy\t S-1.npy   T-9.npy\n",
            "A-6.npy  D-15.npy  E-10.npy  E-8.npy  G-3.npy  P-10.npy  S-2.npy\n",
            "A-7.npy  D-16.npy  E-11.npy  E-9.npy  G-4.npy  P-11.npy  T-10.npy\n",
            "A-8.npy  D-1.npy   E-12.npy  F-1.npy  G-6.npy  P-14.npy  T-12.npy\n",
            "A-9.npy  D-2.npy   E-13.npy  F-2.npy  G-7.npy  P-15.npy  T-13.npy\n",
            "B-1.npy  D-3.npy   E-1.npy   F-3.npy  M-1.npy  P-1.npy\t T-1.npy\n",
            "C-1.npy  D-4.npy   E-2.npy   F-4.npy  M-2.npy  P-2.npy\t T-2.npy\n"
          ]
        }
      ],
      "source": [
        "!ls data/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkbszwQvHaj2",
        "outputId": "f5b7eee4-177e-4a78-ba77-25435194fb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mtad-gat-pytorch'...\n",
            "remote: Enumerating objects: 6189, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 6189 (delta 11), reused 0 (delta 0), pack-reused 6161\u001b[K\n",
            "Receiving objects: 100% (6189/6189), 920.67 MiB | 42.20 MiB/s, done.\n",
            "Resolving deltas: 100% (2708/2708), done.\n",
            "Updating files: 100% (158/158), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ML4ITS/mtad-gat-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npr1PAhqHkoP",
        "outputId": "4abf3c3d-41ba-4953-be5b-2bf9c5e3f38e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeled_anomalies.csv  msl_train_md.csv  smap_train_md.csv\n"
          ]
        }
      ],
      "source": [
        "!ls mtad-gat-pytorch/datasets/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uMiOZVTH1GF"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZtkZvfp-H0Sb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "JBcspDutIHma",
        "outputId": "696fd3f3-bb4b-4006-f3fc-bcd89f4a82ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Channels :  53\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  chan_id  num_values\n",
              "0     A-1        2880\n",
              "1     A-2        2648\n",
              "2     A-3        2736\n",
              "3     A-4        2690\n",
              "4     A-5         705"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4cacdca-de3f-4a7b-a7a3-7b69221607f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chan_id</th>\n",
              "      <th>num_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A-1</td>\n",
              "      <td>2880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A-2</td>\n",
              "      <td>2648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A-3</td>\n",
              "      <td>2736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A-4</td>\n",
              "      <td>2690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A-5</td>\n",
              "      <td>705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4cacdca-de3f-4a7b-a7a3-7b69221607f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4cacdca-de3f-4a7b-a7a3-7b69221607f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4cacdca-de3f-4a7b-a7a3-7b69221607f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "smap_channels = pd.read_csv('mtad-gat-pytorch/datasets/data/smap_train_md.csv')\n",
        "print(\"Number of Channels : \",len(smap_channels))\n",
        "smap_channels.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byk58oXFIYdp",
        "outputId": "733973b3-6267-435b-a959-e2afc565a20a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "smap_channels = list(smap_channels['chan_id'].values)\n",
        "len(smap_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x83wbB2KIsRk"
      },
      "source": [
        "# Create SMAP Data from Time Series across all the Channel IDs - Each Time Step has 25 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWzB0ojGIpvY",
        "outputId": "4dbacd6b-9264-4059-bdd2-5a11db5ac5ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of SMAP Data :  (135183, 25)\n"
          ]
        }
      ],
      "source": [
        "smap_data =[]\n",
        "\n",
        "for smap_channel in smap_channels:\n",
        "  tmp_data = np.load(os.path.join('data/train/',smap_channel+'.npy'))\n",
        "  smap_data.extend(tmp_data)\n",
        "  #print(smap_data.shape)\n",
        "\n",
        "smap_data = np.array(smap_data)\n",
        "print(\"Shape of SMAP Data : \", smap_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuTEV9HbPB7r",
        "outputId": "968f7ed2-ebdf-432b-e873-2a46105ecd0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.999     , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.999     , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.999     , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.98775593, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.98417906, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.98417906, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "smap_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RlvtETjrPSfV"
      },
      "outputs": [],
      "source": [
        "# Next the Data is scaled using Min-Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5ZJLb5YnPjzM"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "biSnvzUCQFBt"
      },
      "outputs": [],
      "source": [
        "def normalize_data(data, scaler=None):\n",
        "  data = np.asarray(data, dtype=np.float32)\n",
        "  if np.any(sum(np.isnan(data))):\n",
        "    data = np.nan_to_num(data)\n",
        "  \n",
        "  if scaler is None:\n",
        "    scaler=MinMaxScaler()\n",
        "    scaler.fit(data)\n",
        "  data=scaler.transform(data)\n",
        "  print(\"Data normalized\")\n",
        "\n",
        "  return data, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt5KbeyQQmCQ",
        "outputId": "a81912c4-735c-4523-c8a5-83e1e342d6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data normalized\n"
          ]
        }
      ],
      "source": [
        "smap_data_norm, scaler = normalize_data(smap_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0_00FQkQwPY",
        "outputId": "593f1f2c-6fe6-4368-90f3-ea8da7650e3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([135183, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "smap_data_pt = torch.from_numpy(smap_data)\n",
        "smap_data_pt.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXsRFg0BRAQG"
      },
      "source": [
        "# Create Sliding Window Dataset - Breaking down the entire time series into small temporal segments which will be used to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x5hWBnk8Q2QN"
      },
      "outputs": [],
      "source": [
        "class SlidingWindowDataset(Dataset):\n",
        "  def __init__(self, data, window, target_dim=None, horizon=1):\n",
        "    self.data= data\n",
        "    self.window = window\n",
        "    self.target_dim = target_dim\n",
        "    self.horizon = horizon\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    x = self.data[index : index+self.window]\n",
        "    y = self.data[index + self.window : index + self.window + self.horizon]\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data) - self.window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QZ7ZpZovSRcN"
      },
      "outputs": [],
      "source": [
        "Window=100\n",
        "BatchSZ=256\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NUE0Bz4OSaEm"
      },
      "outputs": [],
      "source": [
        "smap_x_y = SlidingWindowDataset(smap_data_pt, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A3USJqvSfMG",
        "outputId": "338bba33-b94d-4010-baf3-79803277baa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SlidingWindowDataset at 0x7fdeaa9302e0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "smap_x_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6g1bXVW7SiXX"
      },
      "outputs": [],
      "source": [
        "def create_data_loaders(train_dataset, batch_size, val_split=0.1, shuffle=True, test_dataset=None):\n",
        "    train_loader, val_loader, test_loader = None, None, None\n",
        "    #if we set ratio 0\n",
        "    if val_split == 0.0:\n",
        "        print(f\"train_size: {len(train_dataset)}\")\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    else:\n",
        "        dataset_size = len(train_dataset)\n",
        "        indices = list(range(dataset_size))\n",
        "        split = int(np.floor(val_split * dataset_size))\n",
        "        if shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "        train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "        train_sampler = SubsetRandomSampler(train_indices)\n",
        "        valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "        # in torch DataLoader we need to set batch_size but, I'm not sure to set \n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "        val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "        print(f\"train_size: {len(train_indices)}\")\n",
        "        print(f\"validation_size: {len(val_indices)}\")\n",
        "\n",
        "    if test_dataset is not None:\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "        print(f\"test_size: {len(test_dataset)}\")\n",
        "    #if test_dataset is None then we return None?\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xtBem4UonIt",
        "outputId": "7f06644b-3995-4c99-fab1-ef6841e36798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_size: 121575\n",
            "validation_size: 13508\n"
          ]
        }
      ],
      "source": [
        "train_dl, val_dl, _ = create_data_loaders(smap_x_y, BatchSZ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQfaJL1KpJzS"
      },
      "source": [
        "- Until now, smap_x_y : is \n",
        "1. slided\n",
        "2. torched from numpy\n",
        "3. extended data -> np.array()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLyUMXCtrFTi",
        "outputId": "445be65a-209d-417c-e3b3-bda2e7e49ed7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fdeaa933400>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "val_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byd9iobTp8JX"
      },
      "source": [
        "> We determine the shape of batch\n",
        "> - X : 256 batch size, 100 window length, 25 #Features\n",
        "\n",
        "> - Y : 256 bathc size, 1 future value, 25 #Features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0KgBEULpH5C",
        "outputId": "30562cb3-761d-459b-c80d-4e48d8ba8973"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 100, 25]), torch.Size([256, 1, 25]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "eg = next(iter(val_dl))\n",
        "eg[0].size(), eg[1].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "InostfaSsE2t"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'mtad-gat-pytorch/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tk7qdkHhsLpP"
      },
      "outputs": [],
      "source": [
        "from modules import (\n",
        "    ConvLayer,\n",
        "    FeatureAttentionLayer,\n",
        "    TemporalAttentionLayer,\n",
        "    GRULayer,\n",
        "    Forecasting_Model,\n",
        "    ReconstructionModel,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "y5X8wfw4slzt"
      },
      "outputs": [],
      "source": [
        "class MTAD_GAT(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_features,\n",
        "        window_size,\n",
        "        out_dim,\n",
        "        kernel_size=7,\n",
        "        feat_gat_embed_dim=None,\n",
        "        time_gat_embed_dim=None,\n",
        "        use_gatv2=True,\n",
        "        gru_n_layers=1,\n",
        "        gru_hid_dim=150,\n",
        "        forecast_n_layers=1,\n",
        "        forecast_hid_dim=150,\n",
        "        recon_n_layers=1,\n",
        "        recon_hid_dim=150,\n",
        "        dropout=0.2,\n",
        "        alpha=0.2\n",
        "    ):\n",
        "        super(MTAD_GAT, self).__init__()\n",
        "\n",
        "        self.conv = ConvLayer(n_features, kernel_size)\n",
        "        self.feature_gat = FeatureAttentionLayer(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2, use_bias = False)\n",
        "        self.temporal_gat = TemporalAttentionLayer(n_features, window_size, dropout, alpha, time_gat_embed_dim, use_gatv2, use_bias = False)\n",
        "        self.gru = GRULayer(3 * n_features, gru_hid_dim, gru_n_layers, dropout)\n",
        "        self.forecasting_model = Forecasting_Model(gru_hid_dim, forecast_hid_dim, out_dim, forecast_n_layers, dropout)\n",
        "        self.recon_model = ReconstructionModel(window_size, gru_hid_dim, recon_hid_dim, out_dim, recon_n_layers, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n",
        "\n",
        "        x = self.conv(x)\n",
        "        h_feat = self.feature_gat(x)\n",
        "        h_temp = self.temporal_gat(x)\n",
        "\n",
        "        h_cat = torch.cat([x, h_feat, h_temp], dim=2)  # (b, n, 3k)\n",
        "\n",
        "        _, h_end = self.gru(h_cat)\n",
        "        h_end = h_end.view(x.shape[0], -1)   # Hidden state for last timestamp\n",
        "\n",
        "        predictions = self.forecasting_model(h_end)\n",
        "        recons = self.recon_model(h_end)\n",
        "\n",
        "        return predictions, recons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cN9ysIXIs9Sz"
      },
      "outputs": [],
      "source": [
        "model = MTAD_GAT(n_features = 25, window_size = 100, out_dim = 25, feat_gat_embed_dim = 256, time_gat_embed_dim = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um7bmL6KtB1p",
        "outputId": "e7730d0a-6be0-49b7-fb60-48c56dcd055c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTAD_GAT(\n",
              "  (conv): ConvLayer(\n",
              "    (padding): ConstantPad1d(padding=(3, 3), value=0.0)\n",
              "    (conv): Conv1d(25, 25, kernel_size=(7,), stride=(1,))\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (feature_gat): FeatureAttentionLayer(\n",
              "    (lin): Linear(in_features=200, out_features=512, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (temporal_gat): TemporalAttentionLayer(\n",
              "    (lin): Linear(in_features=50, out_features=128, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (gru): GRULayer(\n",
              "    (gru): GRU(75, 150, batch_first=True)\n",
              "  )\n",
              "  (forecasting_model): Forecasting_Model(\n",
              "    (layers): ModuleList(\n",
              "      (0): Linear(in_features=150, out_features=150, bias=True)\n",
              "      (1): Linear(in_features=150, out_features=25, bias=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (recon_model): ReconstructionModel(\n",
              "    (decoder): RNNDecoder(\n",
              "      (rnn): GRU(150, 150, batch_first=True)\n",
              "    )\n",
              "    (fc): Linear(in_features=150, out_features=25, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aWKx8uqtHxj",
        "outputId": "6d543b5c-4805-4ab7-a570-64ca4b123994"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 25]), torch.Size([256, 100, 25]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "eg_out = model(eg[0].float().to(device))\n",
        "# First Entity : Future Time Step Forecasted\n",
        "# Second Entity : Reconstructed original input\n",
        "eg_out[0].size(), eg_out[1].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "clZoZuQNt5KH"
      },
      "outputs": [],
      "source": [
        "# Optimizer : Adam lr = 0.001 we use the MSE maybe\n",
        "# Both Forecasting and Reconstruction would use MSE Loss function\n",
        "EPOCHS = 2\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "forecast_criterion = nn.MSELoss()\n",
        "recon_criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiQkaxHlyDJ-",
        "outputId": "d122f193-b4eb-4b1d-a94b-2f45d75040a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(475, 53)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "len(train_dl), len(val_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUV-EtmpygMi"
      },
      "source": [
        "# Training Loop, Final Loss = Forecasting Loss + Reconstruction Loss, Track Loss on Eval set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WSYIlAPWyFEh"
      },
      "outputs": [],
      "source": [
        "!mkdir model_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0zblHs3ytUs",
        "outputId": "ecc1dcbe-924f-4b98-ef25-cb3e1fb983f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  0\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.10421131647579025\n",
            "Reconstruction Loss :  0.13184312670454768\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.0855248189424488\n",
            "Reconstruction Loss :  0.10180436471586911\n",
            "Epoch :  1\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.08638069228214976\n",
            "Reconstruction Loss :  0.09682324691539598\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.0816673492316436\n",
            "Reconstruction Loss :  0.09119145062825904\n"
          ]
        }
      ],
      "source": [
        "Best_Valid_loss = 999999\n",
        "Best_Epoch=-1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  forecast_b_losses = []\n",
        "  recon_b_losses = []\n",
        "\n",
        "  print(\"Epoch : \",epoch)\n",
        "  print(\"Training Started ... \")\n",
        "\n",
        "  for batch_idx, batch in enumerate(train_dl):\n",
        "    x = batch[0].to(device).float()\n",
        "    y = batch[1].to(device).float()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    preds, recons = model(x)\n",
        "\n",
        "    forecast_loss = torch.sqrt(forecast_criterion(y.squeeze(1),preds))\n",
        "    recon_loss = torch.sqrt(recon_criterion(x, recons))\n",
        "\n",
        "    loss = forecast_loss + recon_loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    forecast_b_losses.append(forecast_loss.item())\n",
        "    recon_b_losses.append(recon_loss.item())\n",
        "\n",
        "  forecast_b_losses = np.array(forecast_b_losses)\n",
        "  recon_b_losses = np.array(recon_b_losses)\n",
        "\n",
        "  forecast_epoch_loss = np.sqrt((forecast_b_losses ** 2).mean())\n",
        "  recon_epoch_loss = np.sqrt((recon_b_losses**2).mean())\n",
        "  total_epoch_loss = forecast_epoch_loss + recon_epoch_loss\n",
        "\n",
        "  print('Forecasting Loss : ', forecast_epoch_loss)\n",
        "  print('Reconstruction Loss : ', recon_epoch_loss)\n",
        "\n",
        "  forecast_b_losses_eval = []\n",
        "  recon_b_losses_eval = []\n",
        "\n",
        "  print(\"Validation Started ... \")\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(val_dl):\n",
        "      x = batch[0].to(device).float()\n",
        "      y = batch[1].to(device).float()\n",
        "\n",
        "      preds , recons = model(x)\n",
        "\n",
        "      forecast_loss = torch.sqrt(forecast_criterion(y.squeeze(1), preds))\n",
        "      recon_loss = torch.sqrt(recon_criterion(x,recons))\n",
        "      loss = forecast_loss + recon_loss\n",
        "\n",
        "      forecast_b_losses_eval.append(forecast_loss.item())\n",
        "      recon_b_losses_eval.append(recon_loss.item())\n",
        "  \n",
        "  forecast_b_losses_eval = np.array(forecast_b_losses_eval)\n",
        "  recon_b_losses_eval = np.array(recon_b_losses_eval)\n",
        "\n",
        "  forecast_epoch_loss_eval = np.sqrt((forecast_b_losses_eval**2).mean())\n",
        "  recon_epoch_loss_eval = np.sqrt((recon_b_losses_eval**2).mean())\n",
        "\n",
        "  total_epoch_loss_eval = forecast_epoch_loss_eval + recon_epoch_loss_eval\n",
        "\n",
        "  print('Forecasting Loss : ', forecast_epoch_loss_eval)\n",
        "  print('Reconstruction Loss : ', recon_epoch_loss_eval)\n",
        "\n",
        "  if total_epoch_loss_eval < Best_Valid_loss:\n",
        "    Best_Valid_loss = total_epoch_loss_eval\n",
        "    Best_Epoch = epoch\n",
        "\n",
        "    ckpt = {\n",
        "        'Epoch' : epoch,\n",
        "        'Model' : model.state_dict(),\n",
        "        'Optimizer' : optimizer.state_dict(),\n",
        "        'Train_Forecast_loss' : forecast_epoch_loss,\n",
        "        'Train_Recon_loss' : recon_epoch_loss,\n",
        "        'Eval_Forecast_loss' : forecast_epoch_loss_eval,\n",
        "        'Eval_Recon' : recon_epoch_loss_eval\n",
        "    }\n",
        "\n",
        "    torch.save(ckpt, os.path.join('model_checkpoints', str(epoch) + '.pt'))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "F-61HgUt7ueg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf46fbd-2698-41b8-93e3-d8a51eeaab4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTAD_GAT(\n",
              "  (conv): ConvLayer(\n",
              "    (padding): ConstantPad1d(padding=(3, 3), value=0.0)\n",
              "    (conv): Conv1d(25, 25, kernel_size=(7,), stride=(1,))\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (feature_gat): FeatureAttentionLayer(\n",
              "    (lin): Linear(in_features=200, out_features=512, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (temporal_gat): TemporalAttentionLayer(\n",
              "    (lin): Linear(in_features=50, out_features=128, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (gru): GRULayer(\n",
              "    (gru): GRU(75, 150, batch_first=True)\n",
              "  )\n",
              "  (forecasting_model): Forecasting_Model(\n",
              "    (layers): ModuleList(\n",
              "      (0): Linear(in_features=150, out_features=150, bias=True)\n",
              "      (1): Linear(in_features=150, out_features=25, bias=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (recon_model): ReconstructionModel(\n",
              "    (decoder): RNNDecoder(\n",
              "      (rnn): GRU(150, 150, batch_first=True)\n",
              "    )\n",
              "    (fc): Linear(in_features=150, out_features=25, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "best_model = MTAD_GAT(n_features = 25, window_size=100, out_dim=25, feat_gat_embed_dim = 256, time_gat_embed_dim = 64)\n",
        "best_model.load_state_dict(torch.load(os.path.join('model_checkpoints', str(Best_Epoch)+'.pt'))['Model'])\n",
        "best_model.to(device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2QDKg9jTGJT"
      },
      "source": [
        "# Score the Losses on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "k5izLtXbTEK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5752541e-d11a-401d-f104-87dd8c23fd0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Test DataSet :  (427617, 25)\n"
          ]
        }
      ],
      "source": [
        "smap_data_test = []\n",
        "for smap_channel in smap_channels:\n",
        "  tmp_data = np.load(os.path.join('data/test/', smap_channel + '.npy'))\n",
        "  smap_data_test.extend(tmp_data)\n",
        "\n",
        "smap_data_test = np.array(smap_data_test)\n",
        "print(\"Shape of Test DataSet : \", smap_data_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "c3BiqObXT39H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7594c099-0fe9-4723-c828-1e87854fa9e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data normalized\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "smap_data_test_norm, _ = normalize_data(smap_data_test, scaler)\n",
        "smap_data_test_norm = smap_data_test_norm[:10000]\n",
        "smap_data_test_pt = torch.from_numpy(smap_data_test_norm)\n",
        "smap_data_test_pt.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NmcJQr2GUM_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8916793d-9a27-4f7e-fd48-24ea5594d17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Batches in Test Dataloader :  39\n"
          ]
        }
      ],
      "source": [
        "smap_test_x_y = SlidingWindowDataset(smap_data_test_pt,100)\n",
        "test_dl = torch.utils.data.DataLoader(smap_test_x_y, batch_size=256, shuffle=False)\n",
        "print(\"Number of Batches in Test Dataloader : \", len(test_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Jp33b2Un5d"
      },
      "source": [
        "# For Every time steps, Get the Reconstruction & Forecast Loss.\n",
        "\n",
        "# E.g. - If window size = 10, For TS11 - To get Forecasting Loss, we input(TS1 TS2 ... TS10) in model & to get reconstruction loss, input(TS2 TS3 .. TS11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "tTrgaB1-Ucnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751,
          "referenced_widgets": [
            "8cd1f579a0674cb883dc2a444bc83f29",
            "dff72f21ceaa4c0da12e34c6f1c405d0",
            "44d5627293274d92a4c2e80d998dc17e",
            "5dd5c982c61f4c19894f91f2e0e997e5",
            "40168f514fd1469a9f9a790426d4dff9",
            "62db40fd6c1b4a0f9ec68ac3c2f6f6a9",
            "d1a4468acacd4281bc523977f8f4da87",
            "fbafaf09815d400e92c4ae9945c6f564",
            "bb86893ca3d749f6b03558edf08c357b",
            "e97f8832e8094ce6b95c695dc457fa5a",
            "c379e9461c1a4a5892208014e5b2680b"
          ]
        },
        "outputId": "25a4e957-18f6-4ab9-f589-1c517b920c48"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/39 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cd1f579a0674cb883dc2a444bc83f29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(256, 25) (256, 25)\n",
            "(172, 25) (172, 25)\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "#preds=np.empty((1,2))\n",
        "recons = []\n",
        "#recons=np.empty((1,2))\n",
        "with torch.no_grad():\n",
        "  for batch in tqdm(test_dl):\n",
        "    x = batch[0].to(device).float()\n",
        "    y = batch[1].to(device).float()\n",
        "\n",
        "    y_hat, _ =model(x)\n",
        "\n",
        "    recon_x = torch.cat((x[:,1:,:],y),dim=1)\n",
        "    _, window_recon = model(recon_x)\n",
        "    print(window_recon[:,-1,:].detach().cpu().numpy().shape, y_hat.detach().cpu().numpy().shape)\n",
        "    preds.append(y_hat.detach().cpu().numpy())\n",
        "    #preds=np.append(preds,y_hat.detach().cpu().numpy())\n",
        "    \n",
        "    #preds = np.concatenate((preds, y_hat.detach().cpu().numpy()),axis=0)\n",
        "    # Extract last reconstruction only\n",
        "    recons.append(window_recon[:,-1,:].detach().cpu().numpy())\n",
        "    #recons=np.append(recons,window_recon[:,-1,:].detach().cpu().numpy())\n",
        "    #recons = np.concatenate((recons,window_recon[:,-1,:].detach().cpu().numpy()),axis=0)\n",
        "    #print(preds,recons)\n",
        "  preds = np.concatenate(preds, axis=0)\n",
        "  recons = np.concatenate(recons,axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txZ-QqVSXVje"
      },
      "source": [
        "- pred array contains Forecasting loss for all the time steps & all features in test data while recons array contains Reconstruction Loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preds = np.concatenate([preds], axis=0)\n",
        "#recons = np.concatenate([recons],axis=0)"
      ],
      "metadata": {
        "id": "8ruq19koAQmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "1QdoJH4GVmOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae5059f-43db-4e40-f44b-4b6d9b0e9272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9900, 25), (9900, 25))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "preds.shape, recons.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "wYW3EmnDUdPG"
      },
      "outputs": [],
      "source": [
        "scale_scores= True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bVF-IiX36h"
      },
      "source": [
        "# Put the losses in a Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4f4moOWg15a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "_7fugnrYX8Uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b49d798-0ff6-46ce-8381-69f2b4fd9366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9900, 25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-5dc2ce0dba25>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['A_Score_Global'] = anomaly_scores\n"
          ]
        }
      ],
      "source": [
        "actual = smap_data_test_norm[Window:]\n",
        "print(actual.shape)\n",
        "\n",
        "anomaly_scores = np.zeros_like(actual)\n",
        "df = pd.DataFrame()\n",
        "for i in range(preds.shape[1]):\n",
        "  df[f\"Forecast_{i}\"] = preds[:,i]\n",
        "  df[f\"Recon_{i}\"] = recons[:,i]\n",
        "  df[f\"True_{i}\"] = actual[:,i]\n",
        "  a_score = np.sqrt((preds[:,i] - actual[:,i])**2) + np.sqrt((recons[:,i] - actual[:,i])**2)\n",
        "\n",
        "  if scale_scores:\n",
        "    q75, q25 = np.percentile(a_score, [75,25])\n",
        "    iqr = q75 - q25\n",
        "    median = np.median(a_score)\n",
        "    a_score = (a_score - median)/(1+iqr)\n",
        "  anomaly_scores[:,i] = a_score\n",
        "  df[f\"A_Score_{i}\"] = a_score\n",
        "anomaly_scores = np.mean(anomaly_scores, 1)\n",
        "df['A_Score_Global'] = anomaly_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0KMOq5NaJ9m"
      },
      "source": [
        "\n",
        "# Forecast{i}, Recon{i} = Forecast and Reconstruction loss for the i'th feature of the time step, A Score{i} = Forecast+Recon loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hliP_YE2aSBI"
      },
      "source": [
        "# A_Score_Global : Mean of all loss across all features in that time step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqFEJ7kDX8Gk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "NuONRks-VnAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "e90aae83-4ee1-4df6-9163-dae99987a389"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Forecast_0   Recon_0    True_0  A_Score_0  Forecast_1   Recon_1  True_1  \\\n",
              "0       0.990661  0.983908  1.000000  -0.025418    0.007426 -0.005951     0.0   \n",
              "1       0.993305  0.983921  1.000000  -0.027817    0.008087 -0.005970     0.0   \n",
              "2       0.994401  0.983343  1.000000  -0.028284    0.010532 -0.006012     0.0   \n",
              "3       0.997320  0.983095  1.000000  -0.030696    0.012976 -0.006033     0.0   \n",
              "4       0.998966  0.982511  1.000000  -0.031656    0.015931 -0.006043     0.0   \n",
              "...          ...       ...       ...        ...         ...       ...     ...   \n",
              "9895    0.212664  0.025773  0.144039   0.120369   -0.059610  0.258013     0.0   \n",
              "9896    0.166093  0.144286  0.144039  -0.028244   -0.026688  0.101545     0.0   \n",
              "9897    0.112756  0.223830  0.144039   0.051911   -0.013268  0.045539     0.0   \n",
              "9898    0.058413  0.143470  0.139819   0.028420   -0.004275  0.015019     0.0   \n",
              "9899    0.054025  0.144131  0.139819   0.032979   -0.002924  0.012043     0.0   \n",
              "\n",
              "      A_Score_1  Forecast_2   Recon_2  ...  A_Score_22  Forecast_23  Recon_23  \\\n",
              "0     -0.006980   -0.000326 -0.000678  ...   -0.003078     0.000325  0.002116   \n",
              "1     -0.006332   -0.000657 -0.000852  ...   -0.002446     0.000341  0.002084   \n",
              "2     -0.003956   -0.000422 -0.000981  ...   -0.001836     0.000290  0.002089   \n",
              "3     -0.001602   -0.000084 -0.001055  ...   -0.001276     0.000222  0.002085   \n",
              "4      0.001230    0.000234 -0.001100  ...   -0.000620     0.000138  0.002095   \n",
              "...         ...         ...       ...  ...         ...          ...       ...   \n",
              "9895   0.283575   -0.000321  0.005369  ...    0.013354    -0.000127 -0.004091   \n",
              "9896   0.102706   -0.001735 -0.002759  ...    0.011052    -0.000168 -0.007371   \n",
              "9897   0.036404   -0.003427  0.000996  ...   -0.002160     0.000007 -0.004722   \n",
              "9898  -0.001331   -0.003974  0.002768  ...    0.003469     0.000148 -0.003495   \n",
              "9899  -0.005463   -0.003759 -0.000029  ...    0.009458     0.000131 -0.001345   \n",
              "\n",
              "      True_23  A_Score_23  Forecast_24  Recon_24  True_24  A_Score_24  \\\n",
              "0         0.0    0.000082    -0.000048  0.002371      0.0   -0.000461   \n",
              "1         0.0    0.000066    -0.000051  0.002401      0.0   -0.000429   \n",
              "2         0.0    0.000020    -0.000045  0.002400      0.0   -0.000436   \n",
              "3         0.0   -0.000051    -0.000037  0.002378      0.0   -0.000466   \n",
              "4         0.0   -0.000126    -0.000028  0.002377      0.0   -0.000476   \n",
              "...       ...         ...          ...       ...      ...         ...   \n",
              "9895      0.0    0.001855    -0.000450 -0.006210      0.0    0.003767   \n",
              "9896      0.0    0.005168     0.000008 -0.010703      0.0    0.007806   \n",
              "9897      0.0    0.002365     0.000032 -0.007469      0.0    0.004606   \n",
              "9898      0.0    0.001281     0.000019 -0.006464      0.0    0.003590   \n",
              "9899      0.0   -0.000881     0.000007 -0.007699      0.0    0.004810   \n",
              "\n",
              "      A_Score_Global  \n",
              "0          -0.002537  \n",
              "1          -0.002528  \n",
              "2          -0.002235  \n",
              "3          -0.002056  \n",
              "4          -0.001758  \n",
              "...              ...  \n",
              "9895        0.051107  \n",
              "9896        0.018102  \n",
              "9897        0.007270  \n",
              "9898        0.001747  \n",
              "9899        0.002872  \n",
              "\n",
              "[9900 rows x 101 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87cc5a06-bcff-45af-8307-64ccbd06223a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Forecast_0</th>\n",
              "      <th>Recon_0</th>\n",
              "      <th>True_0</th>\n",
              "      <th>A_Score_0</th>\n",
              "      <th>Forecast_1</th>\n",
              "      <th>Recon_1</th>\n",
              "      <th>True_1</th>\n",
              "      <th>A_Score_1</th>\n",
              "      <th>Forecast_2</th>\n",
              "      <th>Recon_2</th>\n",
              "      <th>...</th>\n",
              "      <th>A_Score_22</th>\n",
              "      <th>Forecast_23</th>\n",
              "      <th>Recon_23</th>\n",
              "      <th>True_23</th>\n",
              "      <th>A_Score_23</th>\n",
              "      <th>Forecast_24</th>\n",
              "      <th>Recon_24</th>\n",
              "      <th>True_24</th>\n",
              "      <th>A_Score_24</th>\n",
              "      <th>A_Score_Global</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.990661</td>\n",
              "      <td>0.983908</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.025418</td>\n",
              "      <td>0.007426</td>\n",
              "      <td>-0.005951</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.006980</td>\n",
              "      <td>-0.000326</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003078</td>\n",
              "      <td>0.000325</td>\n",
              "      <td>0.002116</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>0.002371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000461</td>\n",
              "      <td>-0.002537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.993305</td>\n",
              "      <td>0.983921</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.027817</td>\n",
              "      <td>0.008087</td>\n",
              "      <td>-0.005970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.006332</td>\n",
              "      <td>-0.000657</td>\n",
              "      <td>-0.000852</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002446</td>\n",
              "      <td>0.000341</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>-0.000051</td>\n",
              "      <td>0.002401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000429</td>\n",
              "      <td>-0.002528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.994401</td>\n",
              "      <td>0.983343</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.028284</td>\n",
              "      <td>0.010532</td>\n",
              "      <td>-0.006012</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.003956</td>\n",
              "      <td>-0.000422</td>\n",
              "      <td>-0.000981</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001836</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>0.002089</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>-0.000045</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000436</td>\n",
              "      <td>-0.002235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.997320</td>\n",
              "      <td>0.983095</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.030696</td>\n",
              "      <td>0.012976</td>\n",
              "      <td>-0.006033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.001602</td>\n",
              "      <td>-0.000084</td>\n",
              "      <td>-0.001055</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001276</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.002085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000051</td>\n",
              "      <td>-0.000037</td>\n",
              "      <td>0.002378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000466</td>\n",
              "      <td>-0.002056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.998966</td>\n",
              "      <td>0.982511</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.031656</td>\n",
              "      <td>0.015931</td>\n",
              "      <td>-0.006043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001230</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>-0.001100</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000620</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.002095</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000126</td>\n",
              "      <td>-0.000028</td>\n",
              "      <td>0.002377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000476</td>\n",
              "      <td>-0.001758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9895</th>\n",
              "      <td>0.212664</td>\n",
              "      <td>0.025773</td>\n",
              "      <td>0.144039</td>\n",
              "      <td>0.120369</td>\n",
              "      <td>-0.059610</td>\n",
              "      <td>0.258013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.283575</td>\n",
              "      <td>-0.000321</td>\n",
              "      <td>0.005369</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013354</td>\n",
              "      <td>-0.000127</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>-0.000450</td>\n",
              "      <td>-0.006210</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003767</td>\n",
              "      <td>0.051107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9896</th>\n",
              "      <td>0.166093</td>\n",
              "      <td>0.144286</td>\n",
              "      <td>0.144039</td>\n",
              "      <td>-0.028244</td>\n",
              "      <td>-0.026688</td>\n",
              "      <td>0.101545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102706</td>\n",
              "      <td>-0.001735</td>\n",
              "      <td>-0.002759</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011052</td>\n",
              "      <td>-0.000168</td>\n",
              "      <td>-0.007371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.010703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007806</td>\n",
              "      <td>0.018102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9897</th>\n",
              "      <td>0.112756</td>\n",
              "      <td>0.223830</td>\n",
              "      <td>0.144039</td>\n",
              "      <td>0.051911</td>\n",
              "      <td>-0.013268</td>\n",
              "      <td>0.045539</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036404</td>\n",
              "      <td>-0.003427</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002160</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-0.004722</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002365</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>-0.007469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004606</td>\n",
              "      <td>0.007270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9898</th>\n",
              "      <td>0.058413</td>\n",
              "      <td>0.143470</td>\n",
              "      <td>0.139819</td>\n",
              "      <td>0.028420</td>\n",
              "      <td>-0.004275</td>\n",
              "      <td>0.015019</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.001331</td>\n",
              "      <td>-0.003974</td>\n",
              "      <td>0.002768</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003469</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>-0.003495</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>-0.006464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003590</td>\n",
              "      <td>0.001747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9899</th>\n",
              "      <td>0.054025</td>\n",
              "      <td>0.144131</td>\n",
              "      <td>0.139819</td>\n",
              "      <td>0.032979</td>\n",
              "      <td>-0.002924</td>\n",
              "      <td>0.012043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005463</td>\n",
              "      <td>-0.003759</td>\n",
              "      <td>-0.000029</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009458</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>-0.001345</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000881</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-0.007699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004810</td>\n",
              "      <td>0.002872</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9900 rows × 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87cc5a06-bcff-45af-8307-64ccbd06223a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87cc5a06-bcff-45af-8307-64ccbd06223a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87cc5a06-bcff-45af-8307-64ccbd06223a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fkL18Siv6_P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO9zGCJoIAFpLJlpek0YIHh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cd1f579a0674cb883dc2a444bc83f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dff72f21ceaa4c0da12e34c6f1c405d0",
              "IPY_MODEL_44d5627293274d92a4c2e80d998dc17e",
              "IPY_MODEL_5dd5c982c61f4c19894f91f2e0e997e5"
            ],
            "layout": "IPY_MODEL_40168f514fd1469a9f9a790426d4dff9"
          }
        },
        "dff72f21ceaa4c0da12e34c6f1c405d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62db40fd6c1b4a0f9ec68ac3c2f6f6a9",
            "placeholder": "​",
            "style": "IPY_MODEL_d1a4468acacd4281bc523977f8f4da87",
            "value": "100%"
          }
        },
        "44d5627293274d92a4c2e80d998dc17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbafaf09815d400e92c4ae9945c6f564",
            "max": 39,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb86893ca3d749f6b03558edf08c357b",
            "value": 39
          }
        },
        "5dd5c982c61f4c19894f91f2e0e997e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e97f8832e8094ce6b95c695dc457fa5a",
            "placeholder": "​",
            "style": "IPY_MODEL_c379e9461c1a4a5892208014e5b2680b",
            "value": " 39/39 [01:20&lt;00:00,  1.90s/it]"
          }
        },
        "40168f514fd1469a9f9a790426d4dff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62db40fd6c1b4a0f9ec68ac3c2f6f6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a4468acacd4281bc523977f8f4da87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbafaf09815d400e92c4ae9945c6f564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb86893ca3d749f6b03558edf08c357b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e97f8832e8094ce6b95c695dc457fa5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c379e9461c1a4a5892208014e5b2680b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}